{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Charles & Cole"
      ],
      "metadata": {
        "id": "c4rwulinmAX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "6tBxrRuvgt1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc843749-61c1-4e27-c2a2-66bf9c163ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Unzip the compressed data folder \n",
        "setup directories"
      ],
      "metadata": {
        "id": "m4YspMusmPHe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ewwzGVlfiEC"
      },
      "outputs": [],
      "source": [
        "#unzip data [Charles]\n",
        "#with zipfile.ZipFile(r'/content/drive/MyDrive/UTD/.UTD 2023 Spring/4391/ProjData.zip', 'r') as zip_ref:\n",
        "#    zip_ref.extractall('/content')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip data [Cole]\n",
        "with zipfile.ZipFile(r'/content/drive/MyDrive/Laptop Sync/UTD/CS 4391/Term Project/ProjData.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content')"
      ],
      "metadata": {
        "id": "jrqVd9oKmhZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change all directory names to lowercase\n",
        "!mv /content/ProjData/Test /content/ProjData/test\n",
        "!mv /content/ProjData/Train /content/ProjData/train\n",
        "for folder in ['/content/ProjData/test', '/content/ProjData/train']:\n",
        "    !mv {folder}/Coast {folder}/coast\n",
        "    !mv {folder}/Forest {folder}/forest\n",
        "    !mv {folder}/Bedroom {folder}/bedroom\n",
        "\n",
        "# Define the path to the output directory for resized images\n",
        "!mkdir 'Pre-Processed_files'\n",
        "resized_dir = '/content/Pre-Processed_files'\n",
        "!mkdir 'Histogram_data'\n",
        "hist_dir = '/content/Histogram_data'\n",
        "\n",
        "# Define the path to the train and test images directory\n",
        "train_dirs = ['/content/ProjData/train/coast', '/content/ProjData/train/forest', '/content/ProjData/train/bedroom']\n",
        "test_dirs = ['/content/ProjData/test/coast', '/content/ProjData/test/forest', '/content/ProjData/test/bedroom']"
      ],
      "metadata": {
        "id": "4UroTh94iOVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bd2d083-cbbb-4894-9320-e149937ed8df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/ProjData/test/Coast': No such file or directory\n",
            "mv: cannot stat '/content/ProjData/test/Forest': No such file or directory\n",
            "mv: cannot stat '/content/ProjData/test/Bedroom': No such file or directory\n",
            "mv: cannot stat '/content/ProjData/train/Bedroom': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing\n",
        "resize all training images to 200\\*200 and 50\\*50 size images"
      ],
      "metadata": {
        "id": "N9-ZaCK-l4zK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir '/content/Pre-Processed_files/train'\n",
        "!mkdir '/content/Pre-Processed_files/test'"
      ],
      "metadata": {
        "id": "BDFmUDRSTszV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir '/content/Pre-Processed_files/train/coast/'\n",
        "!mkdir '/content/Pre-Processed_files/train/forest/'\n",
        "!mkdir '/content/Pre-Processed_files/train/bedroom'\n",
        "\n",
        "!mkdir '/content/Pre-Processed_files/test/coast/'\n",
        "!mkdir '/content/Pre-Processed_files/test/forest/'\n",
        "!mkdir '/content/Pre-Processed_files/test/bedroom'"
      ],
      "metadata": {
        "id": "NAbiRohodpTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_brightness(img, avg_brightness):\n",
        "    if avg_brightness < 0.4:\n",
        "        return cv2.convertScaleAbs(img, alpha=1.5, beta=50)\n",
        "    elif avg_brightness > 0.6:\n",
        "        return cv2.convertScaleAbs(img, alpha=0.75, beta=-50)\n",
        "    else:\n",
        "        return img\n",
        "\n",
        "def preprocess_images(image_folder):\n",
        "    images_250 = list()\n",
        "    images_200 = list()\n",
        "    images_50 = list()\n",
        "    labels = list()\n",
        "    preproc_out = \"/content/Pre-Processed_files/train\" if image_folder.find('train') != -1 else \"/content/Pre-Processed_files/test\"\n",
        "    index = 0\n",
        "    for category in [\"coast\", \"forest\", \"bedroom\"]:\n",
        "        category_folder = os.path.join(image_folder, category)\n",
        "        for filename in os.listdir(category_folder):\n",
        "            img_path = os.path.join(category_folder, filename)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            avg_brightness = np.mean(img) / 255\n",
        "            \n",
        "            img = adjust_brightness(img, avg_brightness)\n",
        "            img_200 = cv2.resize(img, (200, 200))\n",
        "            img_50 = cv2.resize(img, (50, 50))\n",
        "            \n",
        "            images_250.append(img)\n",
        "            images_200.append(img_200)\n",
        "            images_50.append(img_50)\n",
        "            labels.append(category)\n",
        "            cv2.imwrite((preproc_out + f\"/{category}/img250_{index}.jpg\"), img)\n",
        "            cv2.imwrite((preproc_out + f\"/{category}/img200_{index}.jpg\"), img_200)\n",
        "            cv2.imwrite((preproc_out + f\"/{category}/img50_{index}.jpg\"), img_50)\n",
        "            index+=1\n",
        "    \n",
        "    return np.array(images_250), np.array(images_200), np.array(images_50), np.array(labels)"
      ],
      "metadata": {
        "id": "iIpg7Vr1sggJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/SIFT_Data/\n",
        "!mkdir /content/SIFT_Data/Train\n",
        "!mkdir /content/SIFT_Data/Test"
      ],
      "metadata": {
        "id": "vCkDc9E4qsKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.\tExtract SIFT features on ALL training images and save the data. \n",
        "def extract_SIFT_features(images, labels, isTest=False, descriptors=500):\n",
        "  features = list()\n",
        "  sift = cv2.SIFT_create()\n",
        "  index = 0\n",
        "\n",
        "  for img in images:\n",
        "    kp, des = sift.detectAndCompute(img, None)\n",
        "    try:\n",
        "      #print(len(des))\n",
        "      if len(des) > descriptors:\n",
        "        des = des[:descriptors,:]\n",
        "      elif len(des) < descriptors:\n",
        "        des = np.pad(des, ((0, descriptors-len(des)),(0,0)), mode='constant')\n",
        "      features.append(des.flatten())\n",
        "      if isTest:\n",
        "        with open(f\"/content/SIFT_Data/Test/test{labels[index]}_{img.shape}_{index}.txt\", 'w') as f:\n",
        "          f.write(np.array2string(des))\n",
        "          f.close()\n",
        "      else:\n",
        "        with open(f\"/content/SIFT_Data/Train/train{labels[index]}_{img.shape}_{index}.txt\", 'w') as f:\n",
        "          f.write(np.array2string(des))\n",
        "          f.close()\n",
        "    except:\n",
        "      print(\"why is this empty\")\n",
        "    \n",
        "    index += 1\n",
        "  print(len(features), features[0].shape, features[-1].shape)\n",
        "  return np.array(features)"
      ],
      "metadata": {
        "id": "WcRBIUL-mxbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.\tExtract Histogram features on ALL training images and save the data. \n",
        "def extract_histogram_features(images, labels, bins=30, isTest=False):\n",
        "    features = []\n",
        "    index = 0\n",
        "    for img in images:\n",
        "        hist = cv2.calcHist([img], [0], None, [bins], [0, 255])\n",
        "        features.append(hist.flatten())\n",
        "        if isTest:\n",
        "          with open(f\"/content/Histogram_data/test_{labels[index]}{index}_{img.shape}.txt\", 'w') as f:\n",
        "            f.write(np.array2string(hist))\n",
        "            f.close()\n",
        "        else:\n",
        "          with open(f\"/content/Histogram_data/train_{labels[index]}{index}_{img.shape}.txt\", 'w') as f:\n",
        "            f.write(np.array2string(hist))\n",
        "            f.close()\n",
        "        index +=1\n",
        "\n",
        "    return np.array(features)"
      ],
      "metadata": {
        "id": "grJDTKdTmzXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform 4 training on the data"
      ],
      "metadata": {
        "id": "SsI4MWm8m9S3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#c.\tRepresent the image using histogram feature data and use Nearest Neighbor classifier\n",
        "def train_classifiers(images_50, hist_features_50, hist_features_200, hist_features_250, labels):\n",
        "    labels = np.array([int(label == \"coast\") + 2 * int(label == \"forest\") for label in labels], dtype=np.float32)\n",
        "    knn_pixels = cv2.ml.KNearest_create()\n",
        "    knn_pixels.train(images_50.reshape(len(images_50), -1).astype(np.float32), cv2.ml.ROW_SAMPLE, labels)\n",
        "\n",
        "    knn_hist_50 = cv2.ml.KNearest_create()\n",
        "    knn_hist_50.train(hist_features_50.astype(np.float32), cv2.ml.ROW_SAMPLE, labels)\n",
        "\n",
        "    knn_hist_200 = cv2.ml.KNearest_create()\n",
        "    knn_hist_200.train(hist_features_200.astype(np.float32), cv2.ml.ROW_SAMPLE, labels)\n",
        "\n",
        "    knn_hist_250 = cv2.ml.KNearest_create()\n",
        "    knn_hist_250.train(hist_features_250.astype(np.float32), cv2.ml.ROW_SAMPLE, labels)\n",
        "\n",
        "    return {'knn_pixels': knn_pixels, 'knn_hist_50': knn_hist_50, 'knn_hist_200' : knn_hist_200, 'knn_hist_250' : knn_hist_250}"
      ],
      "metadata": {
        "id": "xwnVJu3ynCgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#d.\tRepresent the image using SIFT feature data and use linear SVM classifier"
      ],
      "metadata": {
        "id": "ewHoO5z3nCVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_SIFT_classifiers(SIFT_50, SIFT_200, SIFT_250, labels, maxIter = 250, tol = 1e-6, c=0.01):\n",
        "\n",
        "  knn_SIFT_200 = cv2.ml.KNearest_create()\n",
        "  knn_SIFT_200.train(SIFT_200.astype(np.float32), cv2.ml.ROW_SAMPLE, labels)\n",
        "\n",
        "  knn_SIFT_250 = cv2.ml.KNearest_create()\n",
        "  knn_SIFT_250.train(SIFT_250.astype(np.float32), cv2.ml.ROW_SAMPLE, labels)\n",
        "\n",
        "  svm_SIFT_200 = cv2.ml.SVM_create()\n",
        "  svm_SIFT_200.setType(cv2.ml.SVM_C_SVC); svm_SIFT_200.setKernel(cv2.ml.SVM_LINEAR); svm_SIFT_200.setC(c)\n",
        "  svm_SIFT_200.setTermCriteria((cv2.TERM_CRITERIA_MAX_ITER, maxIter, tol))\n",
        "  svm_SIFT_200.train(SIFT_200.astype(np.float32), cv2.ml.ROW_SAMPLE, np.argmax(labels, axis=1))\n",
        "\n",
        "  svm_SIFT_250 = cv2.ml.SVM_create()\n",
        "  svm_SIFT_250.setType(cv2.ml.SVM_C_SVC); svm_SIFT_250.setKernel(cv2.ml.SVM_LINEAR); svm_SIFT_250.setC(c)\n",
        "  svm_SIFT_250.setTermCriteria((cv2.TERM_CRITERIA_MAX_ITER, maxIter, tol))\n",
        "  svm_SIFT_250.train(SIFT_250.astype(np.float32), cv2.ml.ROW_SAMPLE, np.argmax(labels, axis=1))\n",
        "\n",
        "  return {'knn_SIFT_200' : knn_SIFT_200, 'knn_SIFT_250' : knn_SIFT_250, 'svm_SIFT_200': svm_SIFT_200, 'svm_SIFT_250' : svm_SIFT_250}"
      ],
      "metadata": {
        "id": "uvyz0cpjnbbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the trained classifiers\n",
        "Report Accuracy, False Positives, and False Negatives"
      ],
      "metadata": {
        "id": "rbeYVTrAnIC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_categorical(labels, classnum=3):\n",
        "  ret = np.zeros((len(labels), classnum))\n",
        "  for i, label in enumerate(labels):\n",
        "    #print(i, label)\n",
        "    ret[i, int(label)] = 1.0\n",
        "  return ret.astype(np.float32)"
      ],
      "metadata": {
        "id": "B15MmbO4x83B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_score(true_labels, pred_labels):\n",
        "    return np.mean(true_labels == pred_labels)\n",
        "\n",
        "def false_positive_rate(true_labels, pred_labels):\n",
        "    fp = np.sum((true_labels != pred_labels) & (pred_labels == 1))\n",
        "    tn = np.sum((true_labels == pred_labels) & (true_labels == 0))\n",
        "    return fp / (fp + tn)\n",
        "\n",
        "def false_negative_rate(true_labels, pred_labels):\n",
        "    fn = np.sum((true_labels != pred_labels) & (pred_labels == 0))\n",
        "    tp = np.sum((true_labels == pred_labels) & (true_labels == 1))\n",
        "    return fn / (fn + tp)\n",
        "\n",
        "def evaluate_classifiers(classifiers, test_data, true_labels, knear= 15, SIFT=False):\n",
        "    results = {}\n",
        "    preddict = {}\n",
        "    truedict = {}\n",
        "    oldlab = true_labels\n",
        "    if not SIFT:\n",
        "      true_labels = np.array([int(label == \"coast\") + 2 * int(label == \"forest\") for label in true_labels], dtype=np.float32)\n",
        "    else:\n",
        "      true_labels = to_categorical((np.array([int(label == \"coast\") + 2 * int(label == \"forest\") for label in true_labels], dtype=np.float32)), 3)\n",
        "    isSVM = False\n",
        "    for name, clf in classifiers.items():\n",
        "        try:\n",
        "          _, pred_labels, _, _ = clf.findNearest(test_data[name].astype(np.float32), k=knear)\n",
        "          if not SIFT:\n",
        "            pred_labels = pred_labels.ravel()\n",
        "        except AttributeError:\n",
        "            isSVM = True\n",
        "            pred_labels = clf.predict(test_data[name].astype(np.float32))[1]\n",
        "        preddict[name] = pred_labels\n",
        "        truedict[name] = true_labels\n",
        "\n",
        "        if isSVM:\n",
        "          true_labels = np.array([int(label == \"coast\") + 2 * int(label == \"forest\") for label in oldlab], dtype=np.float32)\n",
        "          \n",
        "\n",
        "        accuracy = accuracy_score(true_labels, pred_labels)\n",
        "        false_positive = false_positive_rate(true_labels, pred_labels)\n",
        "        false_negative = false_negative_rate(true_labels, pred_labels)\n",
        "\n",
        "        results[name] = {\n",
        "            'accuracy': accuracy,\n",
        "            'false_positive_rate': false_positive,\n",
        "            'false_negative_rate': false_negative,\n",
        "        }\n",
        "\n",
        "    return results, preddict, truedict"
      ],
      "metadata": {
        "id": "4O_3D22ZswL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printResults(results):\n",
        "  for classifier_name, metrics in results.items():\n",
        "    print(f\"Results for {classifier_name}:\")\n",
        "    print(f\"  Accuracy: {metrics['accuracy'] * 100:.2f}%\")\n",
        "    print(f\"  False Positive Rate: {metrics['false_positive_rate'] * 100:.2f}%\")\n",
        "    print(f\"  False Negative Rate: {metrics['false_negative_rate'] * 100:.2f}%\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "wxumGUYP3Cvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img200bins = 50\n",
        "img250bins = 100\n",
        "\n",
        "img50descriptors = 30\n",
        "img200descriptors = 600\n",
        "img250descriptors = 6000\n",
        "\n",
        "train_images_250, train_images_200, train_images_50, train_labels = preprocess_images('/content/ProjData/train')\n",
        "\n",
        "hist_features_50 = extract_histogram_features(train_images_50, labels=train_labels)\n",
        "hist_features_200 = extract_histogram_features(train_images_200, bins=img200bins, labels=train_labels)\n",
        "hist_features_250 = extract_histogram_features(train_images_250, bins= img250bins, labels=train_labels)\n",
        "\n",
        "SIFT_features_50 = extract_SIFT_features(train_images_50, train_labels, descriptors=img50descriptors)\n",
        "SIFT_features_200 = extract_SIFT_features(train_images_200, train_labels, descriptors=img200descriptors)\n",
        "SIFT_features_250 = extract_SIFT_features(train_images_250, train_labels, descriptors=img250descriptors)\n",
        "\n",
        "test_images_250, test_images_200, test_images_50, test_labels = preprocess_images('/content/ProjData/test')\n",
        "\n",
        "test_hist_features_50 = extract_histogram_features(test_images_50, labels=test_labels, isTest = True)\n",
        "test_hist_features_200 = extract_histogram_features(test_images_200, labels= test_labels, bins=img200bins, isTest = True)\n",
        "test_hist_features_250 = extract_histogram_features(test_images_250, labels= test_labels, bins=img250bins, isTest = True)\n",
        "\n",
        "test_SIFT_features_50 = extract_SIFT_features(test_images_50, test_labels, isTest = True, descriptors=img50descriptors)\n",
        "test_SIFT_features_200 = extract_SIFT_features(test_images_200, test_labels, isTest = True, descriptors= img200descriptors)\n",
        "test_SIFT_features_250 = extract_SIFT_features(test_images_250, test_labels, isTest = True, descriptors= img250descriptors)\n"
      ],
      "metadata": {
        "id": "uXsp9a9h3dDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb6cd34-ff54-4932-d7c0-67b9213a2d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "why is this empty\n",
            "299 (3840,) (3840,)\n",
            "300 (76800,) (76800,)\n",
            "300 (768000,) (768000,)\n",
            "why is this empty\n",
            "why is this empty\n",
            "why is this empty\n",
            "why is this empty\n",
            "why is this empty\n",
            "why is this empty\n",
            "why is this empty\n",
            "why is this empty\n",
            "why is this empty\n",
            "why is this empty\n",
            "why is this empty\n",
            "593 (3840,) (3840,)\n",
            "604 (76800,) (76800,)\n",
            "604 (768000,) (768000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_onehotlabels = to_categorical(np.array([int(label == \"coast\") + 2 * int(label == \"forest\") for label in train_labels], dtype=np.float32))\n",
        "train_onehotlabels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iojWS2mNyEvu",
        "outputId": "46502256-1a35-47d4-cef5-a8e77dc78829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_onehotlabels = to_categorical(np.array([int(label == \"coast\") + 2 * int(label == \"forest\") for label in test_labels], dtype=np.float32))\n",
        "test_onehotlabels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUXbKKIOzAjy",
        "outputId": "253653d4-8b4e-42be-bc13-b0c09cef7c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(604, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist_classifiers = train_classifiers(train_images_50, hist_features_50, hist_features_200, hist_features_250, train_labels)\n",
        "sift_classifiers = train_SIFT_classifiers(SIFT_features_50, SIFT_features_200, SIFT_features_250, train_onehotlabels)\n",
        "\n",
        "test_data_hist = {\n",
        "    'knn_pixels': test_images_50.reshape(len(test_images_50), -1),\n",
        "    'knn_hist_50': test_hist_features_50.astype(np.float32),\n",
        "    'knn_hist_200': test_hist_features_200.astype(np.float32),\n",
        "    'knn_hist_250': test_hist_features_250.astype(np.float32)\n",
        "}\n",
        "\n",
        "test_data_sift = {\n",
        "    'knn_SIFT_200' : test_SIFT_features_200,\n",
        "    'knn_SIFT_250' : test_SIFT_features_250,\n",
        "    'svm_SIFT_200' : test_SIFT_features_200,\n",
        "    'svm_SIFT_250' : test_SIFT_features_250\n",
        "}\n",
        "\n",
        "hist_results,_,_ = evaluate_classifiers(hist_classifiers, test_data_hist, test_labels, knear=3)\n",
        "sift_results, spred, strue = evaluate_classifiers(sift_classifiers, test_data_sift, test_labels, knear=3, SIFT=True)\n",
        "\n",
        "printResults(hist_results)\n",
        "printResults(sift_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ6SivDRCUgS",
        "outputId": "6fb4cd2b-47ca-49ca-e52b-afb15c34486b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for knn_pixels:\n",
            "  Accuracy: 45.70%\n",
            "  False Positive Rate: 94.72%\n",
            "  False Negative Rate: 12.31%\n",
            "\n",
            "Results for knn_hist_50:\n",
            "  Accuracy: 50.50%\n",
            "  False Positive Rate: 28.12%\n",
            "  False Negative Rate: 71.19%\n",
            "\n",
            "Results for knn_hist_200:\n",
            "  Accuracy: 50.99%\n",
            "  False Positive Rate: 24.72%\n",
            "  False Negative Rate: 68.21%\n",
            "\n",
            "Results for knn_hist_250:\n",
            "  Accuracy: 51.32%\n",
            "  False Positive Rate: 28.00%\n",
            "  False Negative Rate: 65.33%\n",
            "\n",
            "Results for knn_SIFT_200:\n",
            "  Accuracy: 58.06%\n",
            "  False Positive Rate: 25.83%\n",
            "  False Negative Rate: 74.17%\n",
            "\n",
            "Results for knn_SIFT_250:\n",
            "  Accuracy: 57.06%\n",
            "  False Positive Rate: 28.81%\n",
            "  False Negative Rate: 71.19%\n",
            "\n",
            "Results for svm_SIFT_200:\n",
            "  Accuracy: 34.70%\n",
            "  False Positive Rate: 80.34%\n",
            "  False Negative Rate: 57.66%\n",
            "\n",
            "Results for svm_SIFT_250:\n",
            "  Accuracy: 35.14%\n",
            "  False Positive Rate: 81.84%\n",
            "  False Negative Rate: 55.25%\n",
            "\n"
          ]
        }
      ]
    }
  ]
}